{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T09:40:29.678451Z",
     "start_time": "2025-03-08T09:40:03.603258Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import hanlp\n",
    "\n",
    "# ğŸ“Œ 1. HanLP í† í°í™” ëª¨ë¸ ë¡œë“œ\n",
    "segmenter = hanlp.load(\"CTB9_TOK_ELECTRA_BASE_CRF\")\n",
    "\n",
    "# ğŸ“Œ 2. ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "chinese_stopwords = set([\n",
    "    \"çš„\", \"äº†\", \"åœ¨\", \"æ˜¯\", \"å’Œ\", \"ä¸\", \"ä¹Ÿ\", \"æœ‰\", \"å¯¹\", \"å°±\", \"ä»¥\", \"å°†\", \"è¦\",\n",
    "    \"ä½†\", \"å…¶\", \"è€Œ\", \"æ­¤\", \"æˆ‘ä»¬\", \"ä»–ä»¬\", \"ä½ ä»¬\", \"å¯ä»¥\", \"ä½†æ˜¯\", \"è¿™æ ·\", \"è¿™ä¸ª\",\n",
    "    \"å…¶ä¸­\", \"å…¶ä¸­ä¹‹ä¸€\", \"åŒ…æ‹¬\", \"æ ¹æ®\", \"ç”±äº\", \"é€šè¿‡\", \"æ­¤å¤–\", \"åŒæ—¶\",\n",
    "    \"è®°è€…\", \"æ–°é—»\", \"åª’ä½“\", \"é‡‡è®¿\", \"å‘è¡¨\", \"å®£å¸ƒ\", \"é€éœ²\", \"ä»‹ç»\", \"æŠ¥é“ç§°\",\n",
    "    \"æŒ‡å‡º\", \"å¼ºè°ƒ\", \"è¯å®\", \"æ‰¿è®¤\", \"è®¤ä¸º\", \"è¯„ä»·\", \"è¯„è®º\", \"æåˆ°\", \"è§£é‡Š\", \"åˆ†æ\",\n",
    "    \"æ€»ç»“\", \"é¢„æµ‹\", \"é¢„è®¡\", \"å…³æ³¨\", \"åæ˜ \", \"è¯´æ˜\", \"è¿›ä¸€æ­¥\",\n",
    "    \"ä»Šå¤©\", \"æ˜¨å¤©\", \"æ˜å¤©\", \"æ—¥å‰\", \"è¿‘æ—¥\", \"æœ¬å‘¨\", \"ä¸Šå‘¨\", \"ä¸‹å‘¨\", \"ç›®å‰\",\n",
    "    \"ç°åœ¨\", \"è¿‡å»\", \"æœªæ¥\", \"ä»Šå¹´\", \"å»å¹´\", \"æ˜å¹´\", \"æ­¤å‰\", \"éšå\", \"å½“åœ°\",\n",
    "    \"æ”¿åºœ\", \"æœºæ„\", \"ç›¸å…³\", \"éƒ¨é—¨\", \"å®˜å‘˜\", \"é¢†å¯¼äºº\", \"ä»£è¡¨\", \"å‘è¨€äºº\", \"éƒ¨é•¿\", \"äº‹åŠ¡\", \"å§”å‘˜ä¼š\",\n",
    "    \"ä¸€\", \"äºŒ\", \"ä¸‰\", \"è¿™\", \"ä¸\", \"å¯èƒ½\", \"éƒ½\", \"æ‰\", \"å¯\", \"ä¸€ç›´\", \"åˆ°\", \"å¦‚æœ\", \"å°†\",\n",
    "    \"å¸¦æ¥\", \"ååˆ†\", \"ç§°\", \"ä¸ª\", \"æœˆ\", \"æ¬¡\", \"å› \", \"å› æ­¤\", \"è®¤ä¸º\", \"å¦‚æœ\", \"æœ€\", \"å³\",\n",
    "    \"å½“å¤©\", \"å› ä¸º\", \"æ›¾\", \"å·\", \"ç¬¬\", \"ç­‰\", \"ç›¸å½“\", \"ä¸ª\", \"ä¸¤\", \"å¾ˆ\", \"æ‰€ä»¥\", \"å„ç§\",\n",
    "    \"ä»è€Œ\", \"ä»\", \"ä»¥\", \"ä¸ºäº†\", \"ä»¥åŠ\", \"æ®\", \"å¹¶\", \"è¿‡\", \"å‡ \", \"å·\", \"ç«‹å³\", \"ç›¸å…³\",\n",
    "    \"ç­‰\", \"ç€\", \"äº\", \"ä¸º\", \"è¯´\", \"å´\", \"ä½¿\", \"å›½\", \"è¿˜\", \"å¸¦æ¥\", \"æ¥è¯´\", \"è€Œ\", \"ä¸º\",\n",
    "    \"è‡³\", \"å¯ä»¥\", \"å¾ˆ\", \"ä¼š\", \"é™¤äº†\", \"è¢«\", \"å¤–\", \"ä¹Ÿ\", \"è‹¥\", \"æ›´\", \"å·²ç»\", \"å·²\", \"ç§°\",\n",
    "    \"å¤§å¤§\", \"ä¸ä»…\", \"èƒ½å¤Ÿ\", \"è¿‘æ—¥\", \"å¹¶\", \"å†\", \"ä¸€äº›\", \"æ˜ç¡®\", \"ä½œä¸º\", \"å‘\", \"äº\",\n",
    "    \"è¡¨ç¤º\", \"ä»¥åŠ\"\n",
    "])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\IdeaProjects\\sentiZh\\ZhiTopic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                                   \r"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T10:23:13.824481Z",
     "start_time": "2025-03-08T09:42:28.678667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ğŸ“Œ 3. JSON ë°ì´í„° ë¡œë“œ\n",
    "file_path = \"../data/final_0307.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ğŸ“Œ 4. ë°ì´í„°í”„ë ˆì„ ë³€í™˜\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ğŸ“Œ 5. HanLPë¡œ í† í°í™” ë° ë¶ˆìš©ì–´ ì œê±°\n",
    "def tokenize_and_filter(text):\n",
    "    tokens = segmenter(text)\n",
    "    return \" \".join([word for word in tokens if word not in chinese_stopwords])\n",
    "\n",
    "df[\"tokenized_content\"] = df[\"cleaned_content\"].apply(tokenize_and_filter)\n"
   ],
   "id": "9578b4b4e88270e0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:21:55.582277Z",
     "start_time": "2025-03-08T11:21:55.097574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ğŸ“Œ 6. TF-IDF ë²¡í„°ë¼ì´ì € ì ìš©\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"tokenized_content\"])\n",
    "\n",
    "# ğŸ“Œ 7. ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# ğŸ“Œ 8. ê° ê¸°ì‚¬ë³„ ìƒìœ„ 3ê°œ ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def get_top_keywords(row, top_n=20):\n",
    "    indices = np.argsort(row)[::-1]  # ì¤‘ìš”ë„ ë†’ì€ ìˆœ ì •ë ¬\n",
    "    top_words = [feature_names[i] for i in indices[:top_n]]\n",
    "    return \", \".join(top_words)\n",
    "\n",
    "# ğŸ“Œ 9. ê¸°ì‚¬ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥\n",
    "df[\"keywords\"] = [get_top_keywords(row.toarray().flatten()) for row in tfidf_matrix]\n",
    "\n",
    "# ğŸ“Œ 11. ê²°ê³¼ í™•ì¸ (ìƒìœ„ 10ê°œ ê¸°ì‚¬)\n",
    "print(\"\\nâœ… ê¸°ì‚¬ë³„ TF-IDF í‚¤ì›Œë“œ ìƒìœ„ 10ê°œ:\")\n",
    "print(df[[\"cleaned_content\", \"tokenized_content\", \"keywords\"]].head(10))\n"
   ],
   "id": "39f2457093d40faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê¸°ì‚¬ë³„ TF-IDF í‚¤ì›Œë“œ ìƒìœ„ 10ê°œ:\n",
      "                                     cleaned_content  \\\n",
      "0  7æœˆ5æ—¥æœé²œè¿ç»­å‘å°„7æšå¯¼å¼¹å¼•èµ·å›½é™…ç¤¾ä¼šéœ‡æƒŠã€‚è¿‘æ—¥ç¾æ—¥åœ¨å®‰ç†ä¼šç§¯ææ¨åŠ¨åˆ¶è£æœé²œçš„è®®æ¡ˆå¹¶åŠ ç´§å...   \n",
      "1  è¢«å¤–ç•Œè§†ä¸ºç ´å†°ä¹‹æ—…çš„æœé²œå‰¯å¤–ç›¸é‡‘æ¡‚å† 3æœˆ5è‡³6æ—¥åœ¨çº½çº¦ä¸ç¾å›½åŠ©ç†å›½åŠ¡å¿å¸Œå°”å°±ä¸¤å›½å…³ç³»æ­£å¸¸åŒ–è¿›...   \n",
      "2  ç¥ç§˜è¿™æ˜¯æœé²œç•™ç»™å¤–ç•Œçš„å°è±¡ã€‚ æ­£å› ä¸ºç¥ç§˜ä¸€äº›å›½å®¶çš„æƒ…æŠ¥æœºæ„è´¹å°½å¿ƒæœºé€šè¿‡æŠ•æ”¾å«æ˜Ÿæ´¾é£ä¾¦å¯Ÿæœºç”šè‡³...   \n",
      "3  æ”¹è¿›å‹å¤§æµ¦æ´2å·æ®è¯´å¯æ”»å‡»ç¾æœ¬åœŸç”šè‡³å¯èƒ½å…·æœ‰æ­è½½æ ¸å¼¹å¤´æŠ€æœ¯ æœé²œæ”¿åºœæœ€è¿‘é¢‘ç¹å‘å‡ºæœéŸ©å…³ç³»æ¶åŒ–...   \n",
      "4  æ–°åç½‘é¦–å°”3æœˆ7æ—¥ç”µ è®°è€…ææ‹¯å®‡ å¹²ç‰å…° ç¾å›½æœé²œé—®é¢˜ç‰¹ä½¿æ–¯è’‚èŠ¬åšæ–¯æ²ƒæ€7æ—¥åœ¨éŸ©å›½è¯´ç¾å›½æ„¿æ„...   \n",
      "5  ç¯çƒæ—¶æŠ¥é©»éŸ©å›½ç‰¹çº¦è®°è€…æ²ˆæ¾æŠ¥é“æ®éŸ©è”ç¤¾æŠ¥é“æœé²œäººæ°‘å†›æ€»å‚è°‹éƒ¨2æ—¥å¯¹äºéŸ©ç¾æ—¥3å›½å°±æœé²œè¿œç¨‹ç«ç®­...   \n",
      "6  ä¸­æ–°ç½‘4æœˆ4æ—¥ç”µ ç»¼åˆåª’ä½“æŠ¥é“4æœˆ4æ—¥æœé²œå‘¨è¾¹ç´§å¼ æ€åŠ¿éª¤ç„¶åŠ å‰§æœé²œå®˜æ–¹å·²è¡¨ç¤ºå³å°†å‘å°„å«æ˜Ÿæ—¥éŸ©...   \n",
      "7  æ–°åç½‘åŒ—äº¬ï¼”æœˆï¼‘ï¼”æ—¥ç”µ ç»¼åˆæ–°åç¤¾é©»å¤–è®°è€…æŠ¥é“è”åˆå›½å®‰ç†ä¼šï¼‘ï¼“æ—¥å°±æœé²œå‘å°„é—®é¢˜é€šè¿‡ä¸»å¸­å£°æ˜å...   \n",
      "8  æ–°åç½‘å¹³å£¤ï¼”æœˆï¼‘ï¼˜æ—¥ç”µè®°è€…é«˜æµ©è£å¼ æ»¨é˜³æœé²œäººæ°‘å†›æ€»å‚è°‹éƒ¨å‘è¨€äººï¼‘ï¼˜æ—¥åœ¨å¹³å£¤å‘è¡¨è°ˆè¯è¯´ç¾å›½æ—¥æœ¬...   \n",
      "9  ä¸­å›½å›½äº§èˆªæ¯åŠèˆ°è½½æœºæƒ³åƒå›¾ æ¾³å¤§åˆ©äºšæ‚‰å°¼å…ˆé©±æ™¨æŠ¥4æœˆ29æ—¥æ–‡ç« åŸé¢˜æˆ‘ä»¬çš„é—®é¢˜ä¸­å›½æ˜¯æ•Œæ˜¯å‹ï¼Ÿ ...   \n",
      "\n",
      "                                   tokenized_content  \\\n",
      "0  7æœˆ 5æ—¥ æœé²œ è¿ç»­ å‘å°„ 7 æš å¯¼å¼¹ å¼•èµ· å›½é™… ç¤¾ä¼š éœ‡æƒŠ ã€‚ ç¾ æ—¥ å®‰ç†ä¼š ç§¯æ...   \n",
      "1  å¤–ç•Œ è§†ä¸º ç ´å†° ä¹‹ æ—… æœé²œ å‰¯å¤–ç›¸ é‡‘æ¡‚å†  3æœˆ 5 6æ—¥ çº½çº¦ ç¾å›½ åŠ©ç† å›½åŠ¡å¿ å¸Œ...   \n",
      "2  ç¥ç§˜ æœé²œ ç•™ç»™ å¤–ç•Œ å°è±¡ ã€‚ æ­£ ç¥ç§˜ å›½å®¶ æƒ…æŠ¥ è´¹å°½å¿ƒæœº æŠ•æ”¾ å«æ˜Ÿ æ´¾é£ ä¾¦å¯Ÿæœº ...   \n",
      "3  æ”¹è¿›å‹ å¤§æµ¦æ´ 2 æ®è¯´ æ”»å‡» ç¾ æœ¬åœŸ ç”šè‡³ å…·æœ‰ æ­è½½ æ ¸ å¼¹å¤´ æŠ€æœ¯ æœé²œ æœ€è¿‘ é¢‘ç¹...   \n",
      "4  æ–°åç½‘ é¦–å°” 3æœˆ 7æ—¥ ç”µ ææ‹¯å®‡ å¹²ç‰å…° ç¾å›½ æœé²œ é—®é¢˜ ç‰¹ä½¿ æ–¯è’‚èŠ¬åšæ–¯æ²ƒæ€ 7æ—¥ ...   \n",
      "5  ç¯çƒ æ—¶æŠ¥ é©» éŸ©å›½ ç‰¹çº¦ æ²ˆæ¾ æŠ¥é“ éŸ©è”ç¤¾ æŠ¥é“ æœé²œ äººæ°‘å†› æ€»å‚è°‹éƒ¨ 2æ—¥ å¯¹äº éŸ©...   \n",
      "6  ä¸­æ–°ç½‘ 4æœˆ 4æ—¥ ç”µ ç»¼åˆ æŠ¥é“ 4æœˆ 4æ—¥ æœé²œ å‘¨è¾¹ ç´§å¼  æ€åŠ¿ éª¤ç„¶ åŠ å‰§ æœé²œ å®˜...   \n",
      "7  æ–°åç½‘ åŒ—äº¬ ï¼”æœˆ ï¼‘ï¼”æ—¥ ç”µ ç»¼åˆ æ–°åç¤¾ é©»å¤– æŠ¥é“ è”åˆå›½ å®‰ç†ä¼š ï¼‘ï¼“æ—¥ æœé²œ å‘å°„...   \n",
      "8  æ–°åç½‘ å¹³å£¤ ï¼”æœˆ ï¼‘ï¼˜æ—¥ ç”µ é«˜æµ©è£ å¼ æ»¨é˜³ æœé²œ äººæ°‘å†› æ€»å‚è°‹éƒ¨ ï¼‘ï¼˜æ—¥ å¹³å£¤ è°ˆè¯ ...   \n",
      "9  ä¸­å›½ å›½äº§ èˆªæ¯ åŠ èˆ°è½½æœº æƒ³åƒå›¾ æ¾³å¤§åˆ©äºš æ‚‰å°¼ å…ˆé©± æ™¨æŠ¥ 4æœˆ 29æ—¥ æ–‡ç«  åŸé¢˜ ...   \n",
      "\n",
      "                                            keywords  \n",
      "0  æœé²œ, å¯¼å¼¹, å‘å°„, åˆ¶è£, æ—¥æœ¬, å®‰ç†ä¼š, é˜²å¾¡, ç³»ç»Ÿ, æ¨åŠ¨, å¤ªç©º, è®¡åˆ’, å­¤...  \n",
      "1  ä¼šè°ˆ, æœé²œ, å…³ç³», ç¾å…ƒ, ç¾å›½, è°ˆåˆ¤, é—®é¢˜, å›½åŠ¡å¿, åŒæ–¹, åŒè¾¹, è½å®, 5...  \n",
      "2  æƒ…æŠ¥, æœé²œ, ä¾¦å¯Ÿ, å«æ˜Ÿ, è¿™äº›, ç›‘è§†, äººå‘˜, éŸ©å›½, æ‰‹æ®µ, å›½å®¶, é£æœº, ç¾å›½...  \n",
      "3  å¯¼å¼¹, æœé²œ, è¯•å°„, å…¬é‡Œ, å°„ç¨‹, å‘å°„, æŠ€æœ¯, éŸ©å›½, æ‹…å¿ƒ, æˆåŠŸ, ä¾¦å¯Ÿ, è¯•éªŒ...  \n",
      "4  7æ—¥, æ„¿æ„, æœé²œ, å¯¹è¯, ç¾å›½, æ¥è§¦, 3æœˆ, é¦–å°”, è®¿é—®, è€ƒè™‘, æ­£åœ¨, æœŸé—´...  \n",
      "5  å«æ˜Ÿ, å‘å°„, æ‹¦æˆª, å’Œå¹³, æœé²œ, æ‰“å‡», ç«ç®­, æŠ¥é“, æ°‘æ—, è°´è´£, æ—¥æœ¬, é‡å¤§...  \n",
      "6  å‘å°„, ç«ç®­, 4æ—¥, æœé²œ, å«æ˜Ÿ, 4æœˆ, å³å°†, æ—¶é—´, é—®é¢˜, ææ˜åš, è¯¸å¤š, æ¯”...  \n",
      "7  å®‰ç†ä¼š, å£°æ˜, ä¸»å¸­, æœé²œ, æ¬¢è¿, å‘å°„, æ•¦ä¿ƒ, è”åˆå›½, åŠªåŠ›, å†³è®®, ä¼šè°ˆ, ...  \n",
      "8  å†›æ–¹, å®‰ç†ä¼š, æœé²œ, ä¸»å¸­, å‘å°„, å¹³å£¤, å£°æ˜, å«æ˜Ÿ, ä¼šè°ˆ, ä»»ä½•, å€¡è®®, è°ˆ...  \n",
      "9  ä¸­å›½, æ¾³å¤§åˆ©äºš, ç™½çš®ä¹¦, åŒ—äº¬, é˜²åŠ¡, èµ„æº, å´›èµ·, æ„Ÿåˆ°, è¿™äº›, å†›äº‹, åˆ©ç›Š,...  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:21:56.903626Z",
     "start_time": "2025-03-08T11:21:56.780925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = \"../data/news_with_tokenized_keywords.json\"\n",
    "\n",
    "# ğŸ“Œ í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "columns_to_drop = [\"sentences\", \"filtered_sentences\", \"num_filtered_sentences\", \"num_sentences\", \"ratio\"]\n",
    "\n",
    "# ğŸ“Œ í•´ë‹¹ ì»¬ëŸ¼ ì‚­ì œ (ì¡´ì¬í•˜ì§€ ì•Šì•„ë„ ì—ëŸ¬ ë°œìƒí•˜ì§€ ì•Šë„ë¡ `errors=\"ignore\"` ì„¤ì •)\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# ğŸ“Œ 2. JSON ë¤í”„ë¥¼ ìœ„í•œ ë°ì´í„° ë³€í™˜\n",
    "json_data = df.to_dict(orient=\"records\")  # DataFrame â†’ JSON ë¦¬ìŠ¤íŠ¸ ë³€í™˜\n",
    "\n",
    "# ğŸ“Œ 3. Pretty Print JSON íŒŒì¼ ì €ì¥\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=4, ensure_ascii=False)"
   ],
   "id": "b40da244e4cd4592",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "12e712e627f5d2ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
